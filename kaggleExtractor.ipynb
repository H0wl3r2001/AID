{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle dataset extractor and organizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = 'C:/Users/afons/.kaggle/'\n",
    "\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove feather files, if they exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed data\\Crime_Data_from_2010_to_2019_0.feather\n",
      "Removed data\\Crime_Data_from_2010_to_2019_1.feather\n",
      "Removed data\\Crime_Data_from_2010_to_2019_2.feather\n",
      "Removed data\\Crime_Data_from_2010_to_2019_3.feather\n",
      "Removed data\\Crime_Data_from_2010_to_2019_4.feather\n",
      "Removed data\\Crime_Data_from_2010_to_2019_5.feather\n",
      "Removed data\\Crime_Data_from_2010_to_2019_6.feather\n",
      "Removed data\\Crime_Data_from_2010_to_2019_7.feather\n",
      "Removed data\\Crime_Data_from_2010_to_2019_8.feather\n",
      "Removed data\\Crime_Data_from_2010_to_2019_9.feather\n",
      "Removed data\\Crime_Data_from_2020_to_Present.feather\n",
      "Feather files removed from the 'data' folder.\n"
     ]
    }
   ],
   "source": [
    "data_folder = 'data'\n",
    "\n",
    "# List all files in the data folder\n",
    "files = os.listdir(data_folder)\n",
    "\n",
    "# Remove Feather files (files with a \".feather\" extension)\n",
    "for file in files:\n",
    "    if file.endswith(\".feather\"):\n",
    "        file_path = os.path.join(data_folder, file)\n",
    "        os.remove(file_path)\n",
    "        print(f\"Removed {file_path}\")\n",
    "\n",
    "print(\"Feather files removed from the 'data' folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to the dataset on Kaggle\n",
    "dataset_path = 'sumaiaparveenshupti/los-angeles-crime-data-20102020'\n",
    "\n",
    "# download the dataset to the data folder\n",
    "kaggle.api.dataset_download_files(dataset_path, path='data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the files from zip, get into feather files and remove csv and zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set the path to the zip file\n",
    "zip_path = 'data/los-angeles-crime-data-20102020.zip'\n",
    "\n",
    "# extract all csv files from the zip file\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioned into 10 smaller CSV files in the \"data\" folder.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Create the \"data\" directory if it doesn't exist\n",
    "data_dir = 'data'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Specify the input CSV file and the number of partitions\n",
    "input_file = 'data/Crime_Data_from_2010_to_2019.csv'\n",
    "num_partitions = 10  # Change this to the desired number of partitions\n",
    "\n",
    "# Initialize a list of output CSV writers and files\n",
    "output_writers = []\n",
    "output_files = []\n",
    "\n",
    "# Open the input file\n",
    "with open(input_file, 'r') as input_csv:\n",
    "    # Create a CSV reader for the input file\n",
    "    csv_reader = csv.reader(input_csv)\n",
    "\n",
    "    # Read the CSV header\n",
    "    header = next(csv_reader)\n",
    "\n",
    "    # Open output CSV files and writers for each partition in the \"data\" directory\n",
    "    for i in range(num_partitions):\n",
    "        partition_file = os.path.join(data_dir, f'Crime_Data_from_2010_to_2019_{i}.csv')\n",
    "        output_file = open(partition_file, 'w', newline='')\n",
    "        output_files.append(output_file)\n",
    "        output_writers.append(csv.writer(output_file))\n",
    "\n",
    "        # Write the header to each output file\n",
    "        output_writers[i].writerow(header)\n",
    "\n",
    "    # Iterate through the input CSV and distribute rows to output partitions\n",
    "    current_partition = 0\n",
    "    for row in csv_reader:\n",
    "        output_writers[current_partition].writerow(row)\n",
    "        current_partition = (current_partition + 1) % num_partitions  # Cycle through partitions\n",
    "\n",
    "# Close all output CSV files\n",
    "for output_file in output_files:\n",
    "    output_file.close()\n",
    "\n",
    "print(f'Partitioned into {num_partitions} smaller CSV files in the \"data\" folder.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Crime_Data_from_2010_to_2019.csv...\n",
      "Processing Crime_Data_from_2010_to_2019_0.csv...\n",
      "Processing Crime_Data_from_2010_to_2019_1.csv...\n",
      "Processing Crime_Data_from_2010_to_2019_2.csv...\n",
      "Processing Crime_Data_from_2010_to_2019_3.csv...\n",
      "Processing Crime_Data_from_2010_to_2019_4.csv...\n",
      "Processing Crime_Data_from_2010_to_2019_5.csv...\n",
      "Processing Crime_Data_from_2010_to_2019_6.csv...\n",
      "Processing Crime_Data_from_2010_to_2019_7.csv...\n",
      "Processing Crime_Data_from_2010_to_2019_8.csv...\n",
      "Processing Crime_Data_from_2010_to_2019_9.csv...\n",
      "Processing Crime_Data_from_2020_to_Present.csv...\n"
     ]
    }
   ],
   "source": [
    "# iterate over all csv files in the data folder\n",
    "for file_name in os.listdir('data'):\n",
    "    if file_name.endswith('.csv'):\n",
    "        print(f'Processing {file_name}...')\n",
    "        # read the csv file into a pandas dataframe\n",
    "        df = pd.read_csv(os.path.join('data', file_name))\n",
    "        \n",
    "        # transform the dataframe into more space-efficient datatypes\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == 'int64':\n",
    "                df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "            elif df[col].dtype == 'float64':\n",
    "                df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "        \n",
    "        # save the transformed dataframe as a feather file\n",
    "        feather_path = os.path.join('data', os.path.splitext(file_name)[0] + '.feather')\n",
    "        df.to_feather(feather_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the zip file and the csv files\n",
    "os.remove('data/los-angeles-crime-data-20102020.zip')\n",
    "for file_name in os.listdir('data'):\n",
    "    if file_name.endswith('.csv'):\n",
    "        os.remove(os.path.join('data', file_name))\n",
    "os.remove('data/Crime_Data_from_2010_to_2019.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder size is: 247.90 MB\n"
     ]
    }
   ],
   "source": [
    "def get_folder_size(path):\n",
    "    total_size = 0\n",
    "\n",
    "    # Walk through the directory tree and add up the sizes of all files and subdirectories\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            total_size += os.path.getsize(file_path)\n",
    "\n",
    "    return total_size\n",
    "\n",
    "# Specify the path to the folder you want to measure\n",
    "folder_path = 'data'\n",
    "\n",
    "# Get the folder size in bytes\n",
    "size_in_bytes = get_folder_size(folder_path)\n",
    "\n",
    "# Convert the size to a more human-readable format (e.g., MB, GB)\n",
    "def convert_bytes_to_readable(size_in_bytes):\n",
    "    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if size_in_bytes < 1024.0:\n",
    "            break\n",
    "        size_in_bytes /= 1024.0\n",
    "    return f\"{size_in_bytes:.2f} {unit}\"\n",
    "\n",
    "folder_size_readable = convert_bytes_to_readable(size_in_bytes)\n",
    "\n",
    "print(f\"The folder size is: {folder_size_readable}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spread the feathers into dataframes, after merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DR_NO', 'Date Rptd', 'DATE OCC', 'TIME OCC', 'AREA ', 'AREA NAME',\n",
       "       'Rpt Dist No', 'Part 1-2', 'Crm Cd', 'Crm Cd Desc', 'Mocodes',\n",
       "       'Vict Age', 'Vict Sex', 'Vict Descent', 'Premis Cd', 'Premis Desc',\n",
       "       'Weapon Used Cd', 'Weapon Desc', 'Status', 'Status Desc', 'Crm Cd 1',\n",
       "       'Crm Cd 2', 'Crm Cd 3', 'Crm Cd 4', 'LOCATION', 'Cross Street', 'LAT',\n",
       "       'LON', 'AREA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd1 = pd.read_feather('data/Crime_Data_from_2010_to_2019_0.feather')\n",
    "cd2 = pd.read_feather('data/Crime_Data_from_2010_to_2019_1.feather')\n",
    "cd3 = pd.read_feather('data/Crime_Data_from_2010_to_2019_2.feather')\n",
    "cd4 = pd.read_feather('data/Crime_Data_from_2010_to_2019_3.feather')\n",
    "cd5 = pd.read_feather('data/Crime_Data_from_2010_to_2019_4.feather')\n",
    "cd6 = pd.read_feather('data/Crime_Data_from_2010_to_2019_5.feather')\n",
    "cd7 = pd.read_feather('data/Crime_Data_from_2010_to_2019_6.feather')\n",
    "cd8 = pd.read_feather('data/Crime_Data_from_2010_to_2019_7.feather')\n",
    "cd9 = pd.read_feather('data/Crime_Data_from_2010_to_2019_8.feather')\n",
    "cd10 = pd.read_feather('data/Crime_Data_from_2010_to_2019_9.feather')\n",
    "cd11 = pd.read_feather('data/Crime_Data_from_2020_to_Present.feather')\n",
    "\n",
    "cd = pd.concat([cd1, cd2, cd3, cd4, cd5, cd6, cd7, cd8, cd9, cd10, cd11], axis=0)\n",
    "\n",
    "cd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DR_NO</th>\n",
       "      <th>Crm Cd</th>\n",
       "      <th>Crm Cd Desc</th>\n",
       "      <th>Crm Cd 1</th>\n",
       "      <th>Crm Cd 2</th>\n",
       "      <th>Crm Cd 3</th>\n",
       "      <th>Crm Cd 4</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1307355</td>\n",
       "      <td>900</td>\n",
       "      <td>VIOLATION OF COURT ORDER</td>\n",
       "      <td>900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>Adult Arrest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100100521</td>\n",
       "      <td>624</td>\n",
       "      <td>BATTERY - SIMPLE ASSAULT</td>\n",
       "      <td>624.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100100562</td>\n",
       "      <td>626</td>\n",
       "      <td>INTIMATE PARTNER - SIMPLE ASSAULT</td>\n",
       "      <td>626.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IC</td>\n",
       "      <td>Invest Cont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100100581</td>\n",
       "      <td>624</td>\n",
       "      <td>BATTERY - SIMPLE ASSAULT</td>\n",
       "      <td>624.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>Adult Arrest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100100628</td>\n",
       "      <td>230</td>\n",
       "      <td>ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT</td>\n",
       "      <td>230.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>Adult Arrest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DR_NO  Crm Cd                                     Crm Cd Desc  \\\n",
       "0    1307355     900                        VIOLATION OF COURT ORDER   \n",
       "1  100100521     624                        BATTERY - SIMPLE ASSAULT   \n",
       "2  100100562     626               INTIMATE PARTNER - SIMPLE ASSAULT   \n",
       "3  100100581     624                        BATTERY - SIMPLE ASSAULT   \n",
       "4  100100628     230  ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT   \n",
       "\n",
       "   Crm Cd 1  Crm Cd 2  Crm Cd 3  Crm Cd 4 Status   Status Desc  \n",
       "0     900.0       NaN       NaN       NaN     AA  Adult Arrest  \n",
       "1     624.0       NaN       NaN       NaN     IC   Invest Cont  \n",
       "2     626.0       NaN       NaN       NaN     IC   Invest Cont  \n",
       "3     624.0       NaN       NaN       NaN     AA  Adult Arrest  \n",
       "4     230.0       NaN       NaN       NaN     AA  Adult Arrest  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdc = cd[['DR_NO','Crm Cd', 'Crm Cd Desc', 'Crm Cd 1', 'Crm Cd 2', 'Crm Cd 3', 'Crm Cd 4', 'Status', 'Status Desc']]\n",
    "cdd = cd[['DR_NO', 'Date Rptd', 'DATE OCC', 'TIME OCC']]\n",
    "cda = cd[['DR_NO', 'AREA', 'AREA NAME', 'Rpt Dist No', 'LOCATION', 'Cross Street', 'LAT', 'LON']]\n",
    "cdv = cd[['DR_NO', 'Vict Age', 'Vict Sex', 'Vict Descent']]\n",
    "cds = cd[['DR_NO', 'Premis Cd', 'Premis Desc', 'Mocodes', 'Weapon Used Cd', 'Weapon Desc']]\n",
    "\n",
    "cdc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
